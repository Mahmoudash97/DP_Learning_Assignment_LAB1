{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 02 - Convolutional Neural Networks - Assignment\n",
    "\n",
    "## Goal of the assignment\n",
    "\n",
    "Convolutional Neural Networks are unmatched when it comes to image recognition tasks.\n",
    "In this assignment, you'll apply them to both image recognition and object detection. It will involve designing you own custom CNN, but also applying transfer learning where you'll start from a pre-trained CNN and re-train it to your own classification task. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from scipy import ndimage\n",
    "#import Tensorflow namespaces\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "\n",
    "import pickle\n",
    "\n",
    "# GPU\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malaria Classification\n",
    "\n",
    "Design and train a CNN that is capable to detect whether or not a cell is infected with malaria.\n",
    "\n",
    "First you will design your own CNN. Next you will apply transfer learning to the same recognition task and compare the performance of it to the one of your custom designed CNN.\n",
    "\n",
    "The data can be found in: \n",
    "- './Malaria/train/infected/': images of malaria infected cells used for training purposes.\n",
    "- './Malaria/train/uninfected/': images of healthy cells used for training purposes.\n",
    "- './Malaria/test/infected/': images of malaria infected cells used for testing purposes\n",
    "- './Malaria/test/uninfected/': images of healthy cells used for testing purposes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom built CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "# Read and preprocess images\n",
    "\n",
    "image_size = 100\n",
    "nr_train_images = 1000\n",
    "nr_test_images = 1000\n",
    "infected_train_images = []\n",
    "infected_test_images = []\n",
    "uninfected_train_images = []\n",
    "uninfected_test_images = []\n",
    "y_infected_train = []\n",
    "y_uninfected_train = []\n",
    "y_infected_test = []\n",
    "y_uninfected_test =[]\n",
    "\n",
    "# read infected train_images\n",
    "path = './Malaria/train/infected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_train_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f)) \n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    infected_train_images.append(im)\n",
    "    y_infected_train.append(1)\n",
    "    \n",
    "# read infected test_images\n",
    "\n",
    "path = './Malaria/test/infected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_test_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f))\n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    infected_test_images.append(im)\n",
    "    y_infected_test.append(1)\n",
    "    \n",
    "\n",
    "# read uninfected train_images\n",
    "path = './Malaria/train/uninfected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_train_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f)) \n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    uninfected_train_images.append(im)\n",
    "    y_uninfected_train.append(0)\n",
    "\n",
    "\n",
    "# read uninfected test_images\n",
    "\n",
    "path = './Malaria/test/uninfected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_test_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f)) \n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    uninfected_test_images.append(im)\n",
    "    y_uninfected_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "\n",
    "plt.imshow(uninfected_train_images[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training set and test set. Make sure the datasets are randomized. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image scaling (if necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the neural network on the test set. Use the following metrics: accuracy, recall, \n",
    "# precision, f1-score and the ROC/auRoc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down some conclusions:\n",
    "- What is the achieved accuracy\n",
    "- Is there an imbalance between the performance on the two different classes? Does the neural network have a preference for a certain class?\n",
    "- Visualize some misclassified images (from both classes). \n",
    "- Check if you neural network is suffering from overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve the performance by:\n",
    "- Hyperparameter tuning\n",
    "- Training on more data\n",
    "- Early stopping\n",
    "- Image augmentation. See https://keras.io/preprocessing/image/\n",
    "- Classweight balancing (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning\n",
    "Retrain a VGG19 net for the malaria classification task.\n",
    "Evaluate the performance and compare it to the performance achieved by the custom built CNN.\n",
    "Discuss the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "\n",
    "\n",
    "#modelVGG19 = keras.applications.vgg19.VGG19()\n",
    "modelVGG19 = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(100,100,3))\n",
    "type(modelVGG19)\n",
    "\n",
    "\n",
    "# Convert to a sequential model \n",
    "\n",
    "\n",
    "    \n",
    "# make weights fixed\n",
    "\n",
    "\n",
    "# Add dense layers with softmax activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Car Detection\n",
    "\n",
    "The goal is to build a working car detector capable of finding the location of a car/cars in traffic images. \n",
    "Once the location is determined, a bounding box is drawn around the detected car. See the example below:\n",
    "\n",
    "\n",
    "![alt text](./JupyterImages/cardetectionExample.png \"Title\")\n",
    "\n",
    "You can split the implementation into two main parts:\n",
    "\n",
    "1. Train a CNN as a binary classifier that can distinguish cars from non-cars.\n",
    "2. Now use the trained classifier to discover cars in a complex image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Car classifier\n",
    "\n",
    "The folder \"vehicles\" contains thousands of car images. The folder \"non-vehicles\", contains thousands of images of other objects. \n",
    "\n",
    "- Train and optimize a CNN on these images so it can accurately discriminate cars from non-cars. You have the freedom to decide on architecture of the neural network, the hyperparameters, the size of the training set and test set, etc.\n",
    "\n",
    "- Train a VGG19 network and compare the performance to your own custom CNN. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Attention!**\n",
    "\n",
    "- Due to the large number of images, you might run out of memory (and computational resources). Therefore it's recommended to only use a subset of the entire dataset. Later you can always use a bigger dataset if you systems rersources allow this.\n",
    "\n",
    "- Scale the images to float values raning between 0 and 1:\n",
    "\n",
    "```Python\n",
    "X_car = X_car.astype('float32')`\n",
    "X_car /= 255```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CNN classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.  Sliding window detection\n",
    "\n",
    "Now your CNN has been trained, you can employ it to detect cars in complex road traffic images. \n",
    "In practise you can reside to many different techniques, going from simple (but computationally slow) to sophisticated techniques (like YOLO).\n",
    "In this assignment we'll use the sliding window technique. It means that in a systematic way you classify locally extracted regions of interest.\n",
    "Concretely, scan the images in multiple passes from top left to the bottom right with a window (varying in size). Send the image through the car classifier (custom CNN or VGG19) to determine whether of not the sub-images contains a car. Draw a bounding box in case a car is detected.\n",
    "\n",
    "The folder \"StreetImages\" contains some test images, but feel free to use you own ones.\n",
    "\n",
    "To draw a bounding box, the following piece of Python code can be used:\n",
    "\n",
    "\n",
    "```python\n",
    "def rectangle_perimeter(r0, c0, width, height, shape=None, clip=False):\n",
    "    rr, cc = [r0, r0 + width, r0 + width, r0], [c0, c0, c0 + height, c0 + height]\n",
    "    return skimage.draw.polygon_perimeter(rr, cc, shape=shape, clip=clip)\n",
    "\n",
    "# Drawing the bounding box:\n",
    "rr, cc = rectangle_perimeter(y, x, w, w)\n",
    "image_detected[rr,cc] =255\n",
    "\n",
    "```\n",
    "A car might be surrounded by multiple bounding boxes. Find a way to merge multiple bounding boxes into one bounding box.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking sliding window detection\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
